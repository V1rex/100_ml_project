{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5bbc7ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "id": "157e6ea7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('project_010/train.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25da6c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "id": "0d8fed62",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 1138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "id": "2ca00350",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')"
     },
     "execution_count": 1139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "id": "6c5f7c81",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "id": "1664de27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3e4e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Understanding Features\n",
    "---\n",
    "\n",
    "### Feature Considerations \n",
    "`PassengerId` :Represents the id of the passanger __(should be removed)__\n",
    "\n",
    "`Name ` : __(should be removed)__\n",
    "\n",
    "`Ticket ` : __(consider removal)__\n",
    "\n",
    "`Cabin` :__(Contains to many NaN values, Considering droping)__\n",
    "\n",
    "`Fare `: __(consider removal, as a hypothesis : Pclass is enough that should be tested)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337447c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Categorical Features \n",
    "___\n",
    "\n",
    "## `Pclass`\n",
    "represents the socio-economic status \n",
    "        \n",
    "    - 1 : upper \n",
    "    - 2 : middle \n",
    "    - 3 : Lower \n",
    "    \n",
    "__Hot Encoding should be considered__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "id": "7a639de4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "3    491\n1    216\n2    184\nName: Pclass, dtype: int64"
     },
     "execution_count": 1142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7fc02",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## `Sex`\n",
    "__Hot Encoding should be considered__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "id": "cf8a37b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "male      577\nfemale    314\nName: Sex, dtype: int64"
     },
     "execution_count": 1143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1582e5b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## `Embarked` \n",
    "\n",
    "Port of Embarkation\n",
    "\n",
    "__Hot Encoding should be considered__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "id": "dfb86ec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "S    644\nC    168\nQ     77\nName: Embarked, dtype: int64"
     },
     "execution_count": 1144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589f6c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Numerical Features \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b8d911",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# `Age `\n",
    "**Contains missing values**, that could be imputed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "id": "9931b765",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "24.00    30\n22.00    27\n18.00    26\n19.00    25\n28.00    25\n         ..\n36.50     1\n55.50     1\n0.92      1\n23.50     1\n74.00     1\nName: Age, Length: 88, dtype: int64"
     },
     "execution_count": 1145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ec00e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## `Sibsp and Parch `\n",
    "__Sibsp__ : # of siblings / spouses aboard the Titanic\n",
    "__Parch__ : # of parents / children aboard the Titanic\n",
    "\n",
    "\n",
    "Idea for feature engeneering : \n",
    "Categorical values for married, has kids, has siblings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "id": "1d328aa9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    608\n1    209\n2     28\n4     18\n3     16\n8      7\n5      5\nName: SibSp, dtype: int64"
     },
     "execution_count": 1146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "id": "7e90472b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    678\n1    118\n2     80\n5      5\n3      5\n4      4\n6      1\nName: Parch, dtype: int64"
     },
     "execution_count": 1147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea08e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Target value : `Survived `\n",
    "----\n",
    "Represents the target value for our model \n",
    "\n",
    "    - 0 : did not survive \n",
    "    - 1 : survived \n",
    "    \n",
    "__We note that the number of non-survivers is bigger than the number of survivers, this should be taken care of when creating Train/test splits and when using Cross validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "id": "e894943b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    549\n1    342\nName: Survived, dtype: int64"
     },
     "execution_count": 1148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "id": "bf3f14e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 1149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783a6404",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#  Data cleaning  with Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "id": "c64892d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "class DataCleaner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        #X['Survived'] = y\n",
    "\n",
    "        # Dropping uncessary columns \n",
    "        uncessary_cols = ['Name', 'Ticket', 'Cabin']\n",
    "        \n",
    "        X = X.drop(uncessary_cols, axis='columns')\n",
    "        \n",
    "        #droping duplicates\n",
    "        X.drop_duplicates(inplace=True)\n",
    "        \n",
    "        #dropping missing values for 'Embarked'\n",
    "        X.dropna(subset = [\"Embarked\"], inplace=True)\n",
    "        \n",
    "        #filling Categorical values with their meaning \n",
    "        X['Pclass'] = X['Pclass'].replace({3:'lower', 2:'middle', 1:'upper'})\n",
    "\n",
    "        # y = df['Survived']\n",
    "        # df.drop('Survived', axis=1, inplace=True)\n",
    "\n",
    "        Pass_g_id = X['PassengerId']\n",
    "        X.drop('PassengerId',inplace=True, axis=1)\n",
    "        return X, Pass_g_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "id": "24f5db50",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DropFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,columns_to_drop):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X.drop(self.columns_to_drop, axis = 1,inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "id": "d5543b26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleImputerCustom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables, strategy='mean'):\n",
    "        self.variables = variables\n",
    "        self.strategy = strategy\n",
    "        self.imp = SimpleImputer(missing_values=np.nan,   \n",
    "                    strategy=self.strategy)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        self.imp.fit(X_)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        X_transformed = pd.DataFrame(self.imp.transform(X_), columns= self.variables)\n",
    "        X.drop(self.variables, axis= 1, inplace=True)\n",
    "        X[self.variables] = X_transformed[self.variables].values\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "id": "04de9b13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class OneHotEncodercustom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables=[]):\n",
    "        self.variables = variables\n",
    "        self.ohe = OneHotEncoder(drop='first', \n",
    "            handle_unknown = 'ignore')\n",
    "    def fit(self, X, y = None):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        self.ohe.fit(X_)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for encode in self.variables :\n",
    "            ohe = OneHotEncoder()\n",
    "            transformed = ohe.fit_transform(X[[encode]])\n",
    "\n",
    "            X[ohe.categories_[0]] = transformed.toarray()\n",
    "\n",
    "\n",
    "        X = X.drop(self.variables, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, TransformerMixin\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "class OutlierExtractor(TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Create a transformer to remove outliers. A threshold is set for selection\n",
    "        criteria, and further arguments are passed to the LocalOutlierFactor class\n",
    "\n",
    "        Keyword Args:\n",
    "            neg_conf_val (float): The threshold for excluding samples with a lower\n",
    "               negative outlier factor.\n",
    "\n",
    "        Returns:\n",
    "            object: to be used as a transformer method as part of Pipeline()\n",
    "        \"\"\"\n",
    "\n",
    "        self.threshold = kwargs.pop('neg_conf_val', -10.0)\n",
    "\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def transform(self, X, y):\n",
    "        \"\"\"\n",
    "        Uses LocalOutlierFactor class to subselect data based on some threshold\n",
    "\n",
    "        Returns:\n",
    "            ndarray: subsampled data\n",
    "\n",
    "        Notes:\n",
    "            X should be of shape (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        lcf = LocalOutlierFactor(**self.kwargs)\n",
    "        lcf.fit(X)\n",
    "        return (X[lcf.negative_outlier_factor_ > self.threshold, :],\n",
    "                y[lcf.negative_outlier_factor_ > self.threshold])\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 1155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "id": "e9fa8aaf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n0     lower    male  22.0      1      0   7.2500        S\n1     upper  female  38.0      1      0  71.2833        C\n2     lower  female  26.0      0      0   7.9250        S\n3     upper  female  35.0      1      0  53.1000        S\n4     lower    male  35.0      0      0   8.0500        S\n..      ...     ...   ...    ...    ...      ...      ...\n886  middle    male  27.0      0      0  13.0000        S\n887   upper  female  19.0      0      0  30.0000        S\n888   lower  female   NaN      1      2  23.4500        S\n889   upper    male  26.0      0      0  30.0000        C\n890   lower    male  32.0      0      0   7.7500        Q\n\n[889 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lower</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>upper</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>lower</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>upper</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lower</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>middle</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>upper</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>lower</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>upper</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>lower</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>889 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 1156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['Pclass', 'Embarked','Sex']\n",
    "#for HotEncoding\n",
    "#df = DataCleaner().transform(df)\n",
    "\n",
    "df = DataCleaner().transform(df)[0]\n",
    "#X,y = OutlierExtractor().transform(X,y)\n",
    "\n",
    "y = df['Survived']\n",
    "df.drop(['Survived'], axis=1, inplace = True)\n",
    "X = df\n",
    "#\n",
    "# X\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "outputs": [
    {
     "data": {
      "text/plain": "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n0     lower    male  22.0      1      0   7.2500        S\n1     upper  female  38.0      1      0  71.2833        C\n2     lower  female  26.0      0      0   7.9250        S\n3     upper  female  35.0      1      0  53.1000        S\n4     lower    male  35.0      0      0   8.0500        S\n..      ...     ...   ...    ...    ...      ...      ...\n886  middle    male  27.0      0      0  13.0000        S\n887   upper  female  19.0      0      0  30.0000        S\n888   lower  female   NaN      1      2  23.4500        S\n889   upper    male  26.0      0      0  30.0000        C\n890   lower    male  32.0      0      0   7.7500        Q\n\n[889 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lower</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>upper</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>lower</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>upper</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lower</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>middle</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>upper</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>lower</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>upper</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>lower</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>889 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 1157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "id": "35923582",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n318   upper  female  31.0      0      2  164.8667        S\n705  middle    male  39.0      0      0   26.0000        S\n347   lower  female   NaN      1      0   16.1000        S\n490   lower    male   NaN      1      0   19.9667        S\n441   lower    male  20.0      0      0    9.5000        S\n..      ...     ...   ...    ...    ...       ...      ...\n837   lower    male   NaN      0      0    8.0500        S\n193  middle    male   3.0      1      1   26.0000        S\n630   upper    male  80.0      0      0   30.0000        S\n560   lower    male   NaN      0      0    7.7500        Q\n685  middle    male  25.0      1      2   41.5792        C\n\n[666 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>318</th>\n      <td>upper</td>\n      <td>female</td>\n      <td>31.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>164.8667</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>705</th>\n      <td>middle</td>\n      <td>male</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>26.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>347</th>\n      <td>lower</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>16.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>490</th>\n      <td>lower</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>19.9667</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>441</th>\n      <td>lower</td>\n      <td>male</td>\n      <td>20.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9.5000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>837</th>\n      <td>lower</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>middle</td>\n      <td>male</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>26.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>630</th>\n      <td>upper</td>\n      <td>male</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>560</th>\n      <td>lower</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>middle</td>\n      <td>male</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>41.5792</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>666 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 1158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "id": "08c6fca5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import RFE, SelectKBest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#['Pclass', 'Embarked','Sex']\n",
    "pip = Pipeline([\n",
    "        (\"hot_encode\",OneHotEncodercustom(variables=['Sex','Pclass'])),\n",
    "        (\"imputer\",SimpleImputerCustom(variables=['Age'])),\n",
    "        (\"dropper\",DropFeatures(columns_to_drop=['Fare','Embarked','SibSp','Parch'])),\n",
    "        #('outlier', OutlierExtractor()),\n",
    "        (\"model\", 'passthrough')\n",
    "    ])\n",
    "#(\"std_scaler\",StandardScaler()),\n",
    "# pip.get_params()\n",
    "#pip.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5; 1/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=500\n",
      "[CV 1/5; 1/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=500;, score=0.791 total time=   1.2s\n",
      "[CV 2/5; 1/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=500\n",
      "[CV 2/5; 1/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=500;, score=0.835 total time=   1.1s\n",
      "[CV 3/5; 1/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=500\n",
      "[CV 3/5; 1/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=500;, score=0.805 total time=   0.9s\n",
      "[CV 4/5; 1/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=500\n",
      "[CV 4/5; 1/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=500;, score=0.774 total time=   0.8s\n",
      "[CV 5/5; 1/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=500\n",
      "[CV 5/5; 1/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=500;, score=0.812 total time=   0.8s\n",
      "[CV 1/5; 2/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=1000\n",
      "[CV 1/5; 2/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=1000;, score=0.791 total time=   2.2s\n",
      "[CV 2/5; 2/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=1000\n",
      "[CV 2/5; 2/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=1000;, score=0.835 total time=   2.2s\n",
      "[CV 3/5; 2/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=1000\n",
      "[CV 3/5; 2/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=1000;, score=0.805 total time=   2.2s\n",
      "[CV 4/5; 2/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=1000\n",
      "[CV 4/5; 2/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=1000;, score=0.774 total time=   2.1s\n",
      "[CV 5/5; 2/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=1000\n",
      "[CV 5/5; 2/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=1000;, score=0.812 total time=   1.9s\n",
      "[CV 1/5; 3/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=2000\n",
      "[CV 1/5; 3/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=2000;, score=0.791 total time=   4.6s\n",
      "[CV 2/5; 3/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=2000\n",
      "[CV 2/5; 3/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=2000;, score=0.827 total time=   3.9s\n",
      "[CV 3/5; 3/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=2000\n",
      "[CV 3/5; 3/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=2000;, score=0.805 total time=   3.9s\n",
      "[CV 4/5; 3/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=2000\n",
      "[CV 4/5; 3/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=2000;, score=0.774 total time=   4.0s\n",
      "[CV 5/5; 3/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=2000\n",
      "[CV 5/5; 3/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=2000;, score=0.812 total time=   4.3s\n",
      "[CV 1/5; 4/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=3000\n",
      "[CV 1/5; 4/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=3000;, score=0.799 total time=   6.3s\n",
      "[CV 2/5; 4/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=3000\n",
      "[CV 2/5; 4/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=3000;, score=0.827 total time=   7.0s\n",
      "[CV 3/5; 4/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=3000\n",
      "[CV 3/5; 4/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=3000;, score=0.797 total time=   5.8s\n",
      "[CV 4/5; 4/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=3000\n",
      "[CV 4/5; 4/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=3000;, score=0.774 total time=   6.0s\n",
      "[CV 5/5; 4/24] START model=RandomForestClassifier(), model__max_features=2, model__n_estimators=3000\n",
      "[CV 5/5; 4/24] END model=RandomForestClassifier(), model__max_features=2, model__n_estimators=3000;, score=0.812 total time=   5.6s\n",
      "[CV 1/5; 5/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=500\n",
      "[CV 1/5; 5/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=500;, score=0.791 total time=   1.0s\n",
      "[CV 2/5; 5/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=500\n",
      "[CV 2/5; 5/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=500;, score=0.835 total time=   1.0s\n",
      "[CV 3/5; 5/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=500\n",
      "[CV 3/5; 5/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=500;, score=0.812 total time=   0.9s\n",
      "[CV 4/5; 5/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=500\n",
      "[CV 4/5; 5/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=500;, score=0.774 total time=   0.8s\n",
      "[CV 5/5; 5/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=500\n",
      "[CV 5/5; 5/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=500;, score=0.812 total time=   1.0s\n",
      "[CV 1/5; 6/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=1000\n",
      "[CV 1/5; 6/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=1000;, score=0.791 total time=   2.0s\n",
      "[CV 2/5; 6/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=1000\n",
      "[CV 2/5; 6/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=1000;, score=0.827 total time=   2.2s\n",
      "[CV 3/5; 6/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=1000\n",
      "[CV 3/5; 6/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=1000;, score=0.797 total time=   2.5s\n",
      "[CV 4/5; 6/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=1000\n",
      "[CV 4/5; 6/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=1000;, score=0.774 total time=   1.9s\n",
      "[CV 5/5; 6/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=1000\n",
      "[CV 5/5; 6/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=1000;, score=0.812 total time=   2.3s\n",
      "[CV 1/5; 7/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=2000\n",
      "[CV 1/5; 7/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=2000;, score=0.791 total time=   4.2s\n",
      "[CV 2/5; 7/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=2000\n",
      "[CV 2/5; 7/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=2000;, score=0.827 total time=   3.5s\n",
      "[CV 3/5; 7/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=2000\n",
      "[CV 3/5; 7/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=2000;, score=0.805 total time=   4.0s\n",
      "[CV 4/5; 7/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=2000\n",
      "[CV 4/5; 7/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=2000;, score=0.774 total time=   3.4s\n",
      "[CV 5/5; 7/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=2000\n",
      "[CV 5/5; 7/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=2000;, score=0.812 total time=   3.9s\n",
      "[CV 1/5; 8/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=3000\n",
      "[CV 1/5; 8/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=3000;, score=0.791 total time=   5.2s\n",
      "[CV 2/5; 8/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=3000\n",
      "[CV 2/5; 8/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=3000;, score=0.827 total time=   5.7s\n",
      "[CV 3/5; 8/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=3000\n",
      "[CV 3/5; 8/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=3000;, score=0.812 total time=   5.6s\n",
      "[CV 4/5; 8/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=3000\n",
      "[CV 4/5; 8/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=3000;, score=0.774 total time=   5.6s\n",
      "[CV 5/5; 8/24] START model=RandomForestClassifier(), model__max_features=3, model__n_estimators=3000\n",
      "[CV 5/5; 8/24] END model=RandomForestClassifier(), model__max_features=3, model__n_estimators=3000;, score=0.812 total time=   7.2s\n",
      "[CV 1/5; 9/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=500\n",
      "[CV 1/5; 9/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=500;, score=0.799 total time=   1.3s\n",
      "[CV 2/5; 9/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=500\n",
      "[CV 2/5; 9/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=500;, score=0.820 total time=   0.9s\n",
      "[CV 3/5; 9/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=500\n",
      "[CV 3/5; 9/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=500;, score=0.805 total time=   0.9s\n",
      "[CV 4/5; 9/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=500\n",
      "[CV 4/5; 9/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=500;, score=0.774 total time=   1.0s\n",
      "[CV 5/5; 9/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=500\n",
      "[CV 5/5; 9/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=500;, score=0.812 total time=   0.8s\n",
      "[CV 1/5; 10/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=1000\n",
      "[CV 1/5; 10/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=1000;, score=0.791 total time=   1.6s\n",
      "[CV 2/5; 10/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=1000\n",
      "[CV 2/5; 10/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=1000;, score=0.827 total time=   1.7s\n",
      "[CV 3/5; 10/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=1000\n",
      "[CV 3/5; 10/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=1000;, score=0.805 total time=   1.9s\n",
      "[CV 4/5; 10/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=1000\n",
      "[CV 4/5; 10/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=1000;, score=0.774 total time=   2.6s\n",
      "[CV 5/5; 10/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=1000\n",
      "[CV 5/5; 10/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=1000;, score=0.812 total time=   6.4s\n",
      "[CV 1/5; 11/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=2000\n",
      "[CV 1/5; 11/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=2000;, score=0.799 total time=   6.7s\n",
      "[CV 2/5; 11/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=2000\n",
      "[CV 2/5; 11/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=2000;, score=0.827 total time=   6.0s\n",
      "[CV 3/5; 11/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=2000\n",
      "[CV 3/5; 11/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=2000;, score=0.805 total time=   4.0s\n",
      "[CV 4/5; 11/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=2000\n",
      "[CV 4/5; 11/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=2000;, score=0.774 total time=   4.0s\n",
      "[CV 5/5; 11/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=2000\n",
      "[CV 5/5; 11/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=2000;, score=0.812 total time=   4.7s\n",
      "[CV 1/5; 12/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=3000\n",
      "[CV 1/5; 12/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=3000;, score=0.791 total time=   6.5s\n",
      "[CV 2/5; 12/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=3000\n",
      "[CV 2/5; 12/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=3000;, score=0.827 total time=   7.0s\n",
      "[CV 3/5; 12/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=3000\n",
      "[CV 3/5; 12/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=3000;, score=0.805 total time=   7.0s\n",
      "[CV 4/5; 12/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=3000\n",
      "[CV 4/5; 12/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=3000;, score=0.774 total time=   6.3s\n",
      "[CV 5/5; 12/24] START model=RandomForestClassifier(), model__max_features=4, model__n_estimators=3000\n",
      "[CV 5/5; 12/24] END model=RandomForestClassifier(), model__max_features=4, model__n_estimators=3000;, score=0.812 total time=   6.3s\n",
      "[CV 1/5; 13/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=500\n",
      "[CV 1/5; 13/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=500;, score=0.806 total time=   1.0s\n",
      "[CV 2/5; 13/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=500\n",
      "[CV 2/5; 13/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=500;, score=0.820 total time=   1.1s\n",
      "[CV 3/5; 13/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=500\n",
      "[CV 3/5; 13/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=500;, score=0.812 total time=   1.2s\n",
      "[CV 4/5; 13/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=500\n",
      "[CV 4/5; 13/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=500;, score=0.774 total time=   1.2s\n",
      "[CV 5/5; 13/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=500\n",
      "[CV 5/5; 13/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=500;, score=0.820 total time=   1.3s\n",
      "[CV 1/5; 14/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=1000\n",
      "[CV 1/5; 14/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=1000;, score=0.799 total time=   2.1s\n",
      "[CV 2/5; 14/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=1000\n",
      "[CV 2/5; 14/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=1000;, score=0.827 total time=   2.2s\n",
      "[CV 3/5; 14/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=1000\n",
      "[CV 3/5; 14/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=1000;, score=0.805 total time=   2.2s\n",
      "[CV 4/5; 14/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=1000\n",
      "[CV 4/5; 14/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=1000;, score=0.774 total time=   2.7s\n",
      "[CV 5/5; 14/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=1000\n",
      "[CV 5/5; 14/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=1000;, score=0.812 total time=   2.4s\n",
      "[CV 1/5; 15/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=2000\n",
      "[CV 1/5; 15/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=2000;, score=0.799 total time=   4.3s\n",
      "[CV 2/5; 15/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=2000\n",
      "[CV 2/5; 15/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=2000;, score=0.827 total time=   4.4s\n",
      "[CV 3/5; 15/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=2000\n",
      "[CV 3/5; 15/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=2000;, score=0.797 total time=   3.9s\n",
      "[CV 4/5; 15/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=2000\n",
      "[CV 4/5; 15/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=2000;, score=0.774 total time=   3.6s\n",
      "[CV 5/5; 15/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=2000\n",
      "[CV 5/5; 15/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=2000;, score=0.812 total time=   3.7s\n",
      "[CV 1/5; 16/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=3000\n",
      "[CV 1/5; 16/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=3000;, score=0.799 total time=   5.8s\n",
      "[CV 2/5; 16/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=3000\n",
      "[CV 2/5; 16/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=3000;, score=0.827 total time=   6.3s\n",
      "[CV 3/5; 16/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=3000\n",
      "[CV 3/5; 16/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=3000;, score=0.805 total time=   6.6s\n",
      "[CV 4/5; 16/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=3000\n",
      "[CV 4/5; 16/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=3000;, score=0.774 total time=   6.3s\n",
      "[CV 5/5; 16/24] START model=RandomForestClassifier(), model__max_features=5, model__n_estimators=3000\n",
      "[CV 5/5; 16/24] END model=RandomForestClassifier(), model__max_features=5, model__n_estimators=3000;, score=0.812 total time=   6.3s\n",
      "[CV 1/5; 17/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=500\n",
      "[CV 1/5; 17/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=500;, score=0.806 total time=   1.1s\n",
      "[CV 2/5; 17/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=500\n",
      "[CV 2/5; 17/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=500;, score=0.820 total time=   1.2s\n",
      "[CV 3/5; 17/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=500\n",
      "[CV 3/5; 17/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=500;, score=0.805 total time=   1.0s\n",
      "[CV 4/5; 17/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=500\n",
      "[CV 4/5; 17/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=500;, score=0.774 total time=   1.0s\n",
      "[CV 5/5; 17/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=500\n",
      "[CV 5/5; 17/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=500;, score=0.820 total time=   1.0s\n",
      "[CV 1/5; 18/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=1000\n",
      "[CV 1/5; 18/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=1000;, score=0.806 total time=   1.8s\n",
      "[CV 2/5; 18/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=1000\n",
      "[CV 2/5; 18/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=1000;, score=0.820 total time=   2.4s\n",
      "[CV 3/5; 18/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=1000\n",
      "[CV 3/5; 18/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=1000;, score=0.805 total time=   2.0s\n",
      "[CV 4/5; 18/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=1000\n",
      "[CV 4/5; 18/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=1000;, score=0.774 total time=   1.6s\n",
      "[CV 5/5; 18/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=1000\n",
      "[CV 5/5; 18/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=1000;, score=0.820 total time=   1.7s\n",
      "[CV 1/5; 19/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=2000\n",
      "[CV 1/5; 19/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=2000;, score=0.806 total time=   3.6s\n",
      "[CV 2/5; 19/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=2000\n",
      "[CV 2/5; 19/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=2000;, score=0.820 total time=   3.8s\n",
      "[CV 3/5; 19/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=2000\n",
      "[CV 3/5; 19/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=2000;, score=0.805 total time=   4.0s\n",
      "[CV 4/5; 19/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=2000\n",
      "[CV 4/5; 19/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=2000;, score=0.767 total time=   4.1s\n",
      "[CV 5/5; 19/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=2000\n",
      "[CV 5/5; 19/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=2000;, score=0.820 total time=   3.7s\n",
      "[CV 1/5; 20/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=3000\n",
      "[CV 1/5; 20/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=3000;, score=0.806 total time=   6.8s\n",
      "[CV 2/5; 20/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=3000\n",
      "[CV 2/5; 20/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=3000;, score=0.835 total time=   7.3s\n",
      "[CV 3/5; 20/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=3000\n",
      "[CV 3/5; 20/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=3000;, score=0.805 total time=   7.5s\n",
      "[CV 4/5; 20/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=3000\n",
      "[CV 4/5; 20/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=3000;, score=0.767 total time=   7.8s\n",
      "[CV 5/5; 20/24] START model=RandomForestClassifier(), model__max_features=6, model__n_estimators=3000\n",
      "[CV 5/5; 20/24] END model=RandomForestClassifier(), model__max_features=6, model__n_estimators=3000;, score=0.820 total time=   7.1s\n",
      "[CV 1/5; 21/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=500\n",
      "[CV 1/5; 21/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=500;, score=0.806 total time=   1.4s\n",
      "[CV 2/5; 21/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=500\n",
      "[CV 2/5; 21/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=500;, score=0.827 total time=   1.1s\n",
      "[CV 3/5; 21/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=500\n",
      "[CV 3/5; 21/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=500;, score=0.797 total time=   1.2s\n",
      "[CV 4/5; 21/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=500\n",
      "[CV 4/5; 21/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=500;, score=0.767 total time=   0.9s\n",
      "[CV 5/5; 21/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=500\n",
      "[CV 5/5; 21/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=500;, score=0.820 total time=   0.9s\n",
      "[CV 1/5; 22/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=1000\n",
      "[CV 1/5; 22/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=1000;, score=0.806 total time=   2.3s\n",
      "[CV 2/5; 22/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=1000\n",
      "[CV 2/5; 22/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=1000;, score=0.820 total time=   2.2s\n",
      "[CV 3/5; 22/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=1000\n",
      "[CV 3/5; 22/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=1000;, score=0.805 total time=   1.9s\n",
      "[CV 4/5; 22/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=1000\n",
      "[CV 4/5; 22/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=1000;, score=0.767 total time=   2.1s\n",
      "[CV 5/5; 22/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=1000\n",
      "[CV 5/5; 22/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=1000;, score=0.820 total time=   2.4s\n",
      "[CV 1/5; 23/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=2000\n",
      "[CV 1/5; 23/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=2000;, score=0.806 total time=   4.4s\n",
      "[CV 2/5; 23/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=2000\n",
      "[CV 2/5; 23/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=2000;, score=0.835 total time=   4.8s\n",
      "[CV 3/5; 23/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=2000\n",
      "[CV 3/5; 23/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=2000;, score=0.797 total time=   4.6s\n",
      "[CV 4/5; 23/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=2000\n",
      "[CV 4/5; 23/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=2000;, score=0.767 total time=   4.0s\n",
      "[CV 5/5; 23/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=2000\n",
      "[CV 5/5; 23/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=2000;, score=0.820 total time=   3.8s\n",
      "[CV 1/5; 24/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=3000\n",
      "[CV 1/5; 24/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=3000;, score=0.806 total time=   7.3s\n",
      "[CV 2/5; 24/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=3000\n",
      "[CV 2/5; 24/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=3000;, score=0.827 total time=   7.2s\n",
      "[CV 3/5; 24/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=3000\n",
      "[CV 3/5; 24/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=3000;, score=0.812 total time=   7.2s\n",
      "[CV 4/5; 24/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=3000\n",
      "[CV 4/5; 24/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=3000;, score=0.767 total time=   6.1s\n",
      "[CV 5/5; 24/24] START model=RandomForestClassifier(), model__max_features=7, model__n_estimators=3000\n",
      "[CV 5/5; 24/24] END model=RandomForestClassifier(), model__max_features=7, model__n_estimators=3000;, score=0.820 total time=   6.4s\n",
      "Grid best parameter (max. accuracy):  {'model': RandomForestClassifier(max_features=5, n_estimators=500), 'model__max_features': 5, 'model__n_estimators': 500}\n",
      "Grid best score (accuracy):  0.8063068118056336\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7623318385650224"
     },
     "execution_count": 1181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "normal_params_svc = {\n",
    "    \"model\" : [LogisticRegression(), SVC()],\n",
    "    \"model__C\": [0.001,0.01,0.1,1,10,100,1000,2000,3000,4000],\n",
    "    #\"feat_selector__n_features_to_select\" : range(1,10)\n",
    "}\n",
    "\n",
    "normal_params_decission_tree = {\n",
    "    \"model\" : [RandomForestClassifier()],\n",
    "    \"model__n_estimators\" : [500,1000,2000,3000],\n",
    "    \"model__max_features\" : range(2,8)\n",
    "}\n",
    "#{**normal_params_svc},\n",
    "params = [{**normal_params_decission_tree} ]\n",
    "\n",
    "\n",
    "\n",
    "gs = GridSearchCV(pip, params, scoring='accuracy', verbose=10)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Grid best parameter (max. accuracy): ', gs.best_params_)\n",
    "print('Grid best score (accuracy): ', gs.best_score_)\n",
    "\n",
    "gs.best_estimator_.score(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20264/1229711487.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m#y = gs.best_estimator_.predict(test_data)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mX_data\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mpass_id\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDataCleaner\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_estimator_\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mpass_id\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpass_id\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, X, **predict_params)\u001B[0m\n\u001B[0;32m    456\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtransform\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwith_final\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    457\u001B[0m             \u001B[0mXt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 458\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mpredict_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    459\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    460\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mavailable_if\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_final_estimator_has\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"fit_predict\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    830\u001B[0m             \u001B[0mThe\u001B[0m \u001B[0mpredicted\u001B[0m \u001B[0mclasses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    831\u001B[0m         \"\"\"\n\u001B[1;32m--> 832\u001B[1;33m         \u001B[0mproba\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_proba\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    833\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    834\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_outputs_\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36mpredict_proba\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    872\u001B[0m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    873\u001B[0m         \u001B[1;31m# Check data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 874\u001B[1;33m         \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_X_predict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    875\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    876\u001B[0m         \u001B[1;31m# Assign chunk of trees to jobs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36m_validate_X_predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    603\u001B[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001B[0;32m    604\u001B[0m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 605\u001B[1;33m         \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mDTYPE\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"csr\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    606\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0missparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindices\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mintc\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindptr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mintc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    607\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"No support for np.int64 index based sparse matrices\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    575\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Validation should be done on X, y or both.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    576\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 577\u001B[1;33m             \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"X\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    578\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    579\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    897\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    898\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 899\u001B[1;33m             _assert_all_finite(\n\u001B[0m\u001B[0;32m    900\u001B[0m                 \u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    901\u001B[0m                 \u001B[0minput_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    144\u001B[0m                     \u001B[1;34m\"#estimators-that-handle-nan-values\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    145\u001B[0m                 )\n\u001B[1;32m--> 146\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmsg_err\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    147\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('project_010/test.csv')\n",
    "#y = gs.best_estimator_.predict(test_data)\n",
    "X_data,pass_id = DataCleaner().transform(test_data)\n",
    "y = gs.best_estimator_.predict(X_data)\n",
    "\n",
    "pass_id = pd.DataFrame(pass_id)\n",
    "pass_id['Survived'] = y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "outputs": [],
   "source": [
    "pass_id.to_csv('submission.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}