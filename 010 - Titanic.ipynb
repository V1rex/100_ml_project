{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5bbc7ed",
   "metadata": {},
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "157e6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('project_010/train.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25da6c",
   "metadata": {},
   "source": [
    "# Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0d8fed62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2ca00350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6c5f7c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1664de27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3e4e0",
   "metadata": {},
   "source": [
    "## Understanding Features\n",
    "---\n",
    "\n",
    "### Feature Considerations \n",
    "`PassengerId` :Represents the id of the passanger __(should be removed)__\n",
    "\n",
    "`Name ` : __(should be removed)__\n",
    "\n",
    "`Ticket ` : __(consider removal)__\n",
    "\n",
    "`Cabin` :__(Contains to many NaN values, Considering droping)__\n",
    "\n",
    "`Fare `: __(consider removal, as a hypothesis : Pclass is enough that should be tested)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337447c0",
   "metadata": {},
   "source": [
    "### Categorical Features \n",
    "___\n",
    "\n",
    "## `Pclass`\n",
    "represents the socio-economic status \n",
    "        \n",
    "    - 1 : upper \n",
    "    - 2 : middle \n",
    "    - 3 : Lower \n",
    "    \n",
    "__Hot Encoding should be considered__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7a639de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7fc02",
   "metadata": {},
   "source": [
    "## `Sex`\n",
    "__Hot Encoding should be considered__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "cf8a37b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1582e5b",
   "metadata": {},
   "source": [
    "## `Embarked` \n",
    "\n",
    "Port of Embarkation\n",
    "\n",
    "__Hot Encoding should be considered__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dfb86ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589f6c9",
   "metadata": {},
   "source": [
    "### Numerical Features \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b8d911",
   "metadata": {},
   "source": [
    "## `Age `\n",
    "**Contains missing values**, that could be imputed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9931b765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.00    30\n",
       "22.00    27\n",
       "18.00    26\n",
       "19.00    25\n",
       "28.00    25\n",
       "         ..\n",
       "36.50     1\n",
       "55.50     1\n",
       "0.92      1\n",
       "23.50     1\n",
       "74.00     1\n",
       "Name: Age, Length: 88, dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ec00e",
   "metadata": {},
   "source": [
    "## `Sibsp and Parch `\n",
    "__Sibsp__ : # of siblings / spouses aboard the Titanic\n",
    "__Parch__ : # of parents / children aboard the Titanic\n",
    "\n",
    "\n",
    "Idea for feature engeneering : \n",
    "Categorical values for married, has kids, has siblings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1d328aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    608\n",
       "1    209\n",
       "2     28\n",
       "4     18\n",
       "3     16\n",
       "8      7\n",
       "5      5\n",
       "Name: SibSp, dtype: int64"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7e90472b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    678\n",
       "1    118\n",
       "2     80\n",
       "5      5\n",
       "3      5\n",
       "4      4\n",
       "6      1\n",
       "Name: Parch, dtype: int64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea08e9",
   "metadata": {},
   "source": [
    "## Target value : `Survived `\n",
    "----\n",
    "Represents the target value for our model \n",
    "\n",
    "    - 0 : did not survive \n",
    "    - 1 : survived \n",
    "    \n",
    "__We note that the number of non-survivers is bigger than the number of survivers, this should be taken care of when creating Train/test splits and when using Cross validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e894943b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "bf3f14e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783a6404",
   "metadata": {},
   "source": [
    "#  Data cleaning  with Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7d4726af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "class DataCleaner(BaseEstimator, TransformerMixin):       \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        # Dropping uncessary columns \n",
    "        uncessary_cols = ['PassengerId','Name', 'Ticket', 'Cabin']\n",
    "        \n",
    "        X = X.drop(uncessary_cols, axis='columns')\n",
    "        \n",
    "        #droping duplicates\n",
    "        X.drop_duplicates(inplace=True)\n",
    "        \n",
    "        #dropping missing values for 'Embarked'\n",
    "        X.dropna(subset = [\"Embarked\"], inplace=True)\n",
    "        \n",
    "        #filling Categorical values with their meaning \n",
    "        X['Pclass'] = X['Pclass'].replace({3:'lower', 2:'middle', 1:'upper'})\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "46f5f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,columns_to_drop=[]):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df, y = None):\n",
    "        return X.drop(self.columns_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4f1820bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleImputerCustom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables, strategy='mean'):\n",
    "        self.variables = variables\n",
    "        self.strategy = strategy\n",
    "        self.imp = SimpleImputer(missing_values=np.nan,   \n",
    "                    strategy=self.strategy)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        self.imp.fit(X_)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        X_transformed = pd.DataFrame(self.imp.transform(X_), columns= self.variables)\n",
    "        X.drop(self.variables, axis= 1, inplace=True)\n",
    "        X[self.variables] = X_transformed[self.variables].values\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "11e8b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncodercustom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables=[]):\n",
    "        self.variables = variables\n",
    "        self.ohe = OneHotEncoder(drop='first', \n",
    "            handle_unknown = 'ignore')\n",
    "    def fit(self, X, y = None):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        self.ohe.fit(X_)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        for encode in self.variables :\n",
    "            ohe = OneHotEncoder()\n",
    "            transformed = ohe.fit_transform(X[[encode]])\n",
    "\n",
    "            X[ohe.categories_[0]] = transformed.toarray()\n",
    "\n",
    "\n",
    "        X = X.drop(self.variables, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d0ffa77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lower</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upper</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lower</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>upper</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lower</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>lower</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>upper</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>lower</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>upper</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>lower</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0    lower    male  22.0      1      0   7.2500        S\n",
       "1    upper  female  38.0      1      0  71.2833        C\n",
       "2    lower  female  26.0      0      0   7.9250        S\n",
       "3    upper  female  35.0      1      0  53.1000        S\n",
       "4    lower    male  35.0      0      0   8.0500        S\n",
       "..     ...     ...   ...    ...    ...      ...      ...\n",
       "885  lower  female  39.0      0      5  29.1250        Q\n",
       "887  upper  female  19.0      0      0  30.0000        S\n",
       "888  lower  female   NaN      1      2  23.4500        S\n",
       "889  upper    male  26.0      0      0  30.0000        C\n",
       "890  lower    male  32.0      0      0   7.7500        Q\n",
       "\n",
       "[778 rows x 7 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['Pclass', 'Embarked','Sex']\n",
    "#for HotEncoding \n",
    "df = DataCleaner().transform(df)\n",
    "y = df['Survived']\n",
    "df.drop(['Survived'], axis=1, inplace = True)\n",
    "X = df\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "bce29c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>middle</td>\n",
       "      <td>female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>middle</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>middle</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>middle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>middle</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>upper</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>lower</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.4625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>middle</td>\n",
       "      <td>male</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>lower</td>\n",
       "      <td>male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0542</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>upper</td>\n",
       "      <td>female</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
       "506  middle  female  33.0      0      2   26.0000        S\n",
       "303  middle  female   NaN      0      0   12.3500        Q\n",
       "149  middle    male  42.0      0      0   13.0000        S\n",
       "211  middle  female  35.0      0      0   21.0000        S\n",
       "344  middle    male  36.0      0      0   13.0000        S\n",
       "..      ...     ...   ...    ...    ...       ...      ...\n",
       "872   upper    male  33.0      0      0    5.0000        S\n",
       "205   lower  female   2.0      0      1   10.4625        S\n",
       "714  middle    male  52.0      0      0   13.0000        S\n",
       "631   lower    male  51.0      0      0    7.0542        S\n",
       "779   upper  female  43.0      0      1  211.3375        S\n",
       "\n",
       "[583 rows x 7 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2ab54420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('hot_encode', 'passthrough'),\n",
       "  ('imputer', SimpleImputerCustom(variables=['Age'])),\n",
       "  ('column_drop', 'passthrough'),\n",
       "  ('std_scaler', StandardScaler()),\n",
       "  ('minmax_scaler', MinMaxScaler()),\n",
       "  ('model', LogisticRegression())],\n",
       " 'verbose': False,\n",
       " 'hot_encode': 'passthrough',\n",
       " 'imputer': SimpleImputerCustom(variables=['Age']),\n",
       " 'column_drop': 'passthrough',\n",
       " 'std_scaler': StandardScaler(),\n",
       " 'minmax_scaler': MinMaxScaler(),\n",
       " 'model': LogisticRegression(),\n",
       " 'imputer__strategy': 'mean',\n",
       " 'imputer__variables': ['Age'],\n",
       " 'std_scaler__copy': True,\n",
       " 'std_scaler__with_mean': True,\n",
       " 'std_scaler__with_std': True,\n",
       " 'minmax_scaler__clip': False,\n",
       " 'minmax_scaler__copy': True,\n",
       " 'minmax_scaler__feature_range': (0, 1),\n",
       " 'model__C': 1.0,\n",
       " 'model__class_weight': None,\n",
       " 'model__dual': False,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__intercept_scaling': 1,\n",
       " 'model__l1_ratio': None,\n",
       " 'model__max_iter': 100,\n",
       " 'model__multi_class': 'auto',\n",
       " 'model__n_jobs': None,\n",
       " 'model__penalty': 'l2',\n",
       " 'model__random_state': None,\n",
       " 'model__solver': 'lbfgs',\n",
       " 'model__tol': 0.0001,\n",
       " 'model__verbose': 0,\n",
       " 'model__warm_start': False}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "pip = Pipeline([\n",
    "        (\"hot_encode\",'passthrough'),\n",
    "        (\"imputer\",SimpleImputerCustom(variables=['Age'])),\n",
    "        (\"column_drop\",'passthrough'),\n",
    "        (\"std_scaler\",StandardScaler()),\n",
    "        (\"minmax_scaler\",MinMaxScaler()),\n",
    "        (\"model\", LogisticRegression()),\n",
    "    ])\n",
    "\n",
    "pip.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c6f392ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[CV 1/5; 1/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough\n",
      "[CV 1/5; 1/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 1/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough\n",
      "[CV 2/5; 1/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 1/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough\n",
      "[CV 3/5; 1/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 1/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough\n",
      "[CV 4/5; 1/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 1/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough\n",
      "[CV 5/5; 1/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 2/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 1/5; 2/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 2/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 2/5; 2/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 2/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 3/5; 2/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 2/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 4/5; 2/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 2/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 5/5; 2/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 3/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough\n",
      "[CV 1/5; 3/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 3/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough\n",
      "[CV 2/5; 3/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 3/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough\n",
      "[CV 3/5; 3/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 3/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough\n",
      "[CV 4/5; 3/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 3/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough\n",
      "[CV 5/5; 3/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 4/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 1/5; 4/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 4/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 2/5; 4/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 4/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 3/5; 4/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 4/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 4/5; 4/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 4/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 5/5; 4/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 5/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough\n",
      "[CV 1/5; 5/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 5/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough\n",
      "[CV 2/5; 5/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 5/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough\n",
      "[CV 3/5; 5/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 5/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough\n",
      "[CV 4/5; 5/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 5/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough\n",
      "[CV 5/5; 5/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 6/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 1/5; 6/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 6/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 2/5; 6/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 6/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 3/5; 6/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 6/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 6/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 5/5; 6/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 7/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough\n",
      "[CV 1/5; 7/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 7/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough\n",
      "[CV 2/5; 7/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 7/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough\n",
      "[CV 3/5; 7/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 7/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough\n",
      "[CV 4/5; 7/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 7/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough\n",
      "[CV 5/5; 7/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 8/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler()\n",
      "[CV 1/5; 8/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 8/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler()\n",
      "[CV 2/5; 8/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 8/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler()\n",
      "[CV 3/5; 8/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 8/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler()\n",
      "[CV 4/5; 8/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 8/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler()\n",
      "[CV 5/5; 8/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 9/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough\n",
      "[CV 1/5; 9/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 9/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough\n",
      "[CV 2/5; 9/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 9/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough\n",
      "[CV 3/5; 9/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 9/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough\n",
      "[CV 4/5; 9/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 9/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough\n",
      "[CV 5/5; 9/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 10/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler()\n",
      "[CV 1/5; 10/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 10/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler()\n",
      "[CV 2/5; 10/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 10/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler()\n",
      "[CV 3/5; 10/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 10/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler()\n",
      "[CV 4/5; 10/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 10/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 11/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough\n",
      "[CV 1/5; 11/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 11/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough\n",
      "[CV 2/5; 11/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 11/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough\n",
      "[CV 3/5; 11/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 11/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough\n",
      "[CV 4/5; 11/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 11/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough\n",
      "[CV 5/5; 11/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 12/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler()\n",
      "[CV 1/5; 12/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 12/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler()\n",
      "[CV 2/5; 12/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 12/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler()\n",
      "[CV 3/5; 12/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 12/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler()\n",
      "[CV 4/5; 12/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 12/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler()\n",
      "[CV 5/5; 12/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 13/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough\n",
      "[CV 1/5; 13/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 13/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough\n",
      "[CV 2/5; 13/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 13/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough\n",
      "[CV 3/5; 13/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 13/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough\n",
      "[CV 4/5; 13/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 13/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough\n",
      "[CV 5/5; 13/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 14/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 1/5; 14/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 14/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 2/5; 14/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 14/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 3/5; 14/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 14/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 4/5; 14/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 14/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 5/5; 14/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 15/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough\n",
      "[CV 1/5; 15/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 15/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough\n",
      "[CV 2/5; 15/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 15/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough\n",
      "[CV 3/5; 15/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 15/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough\n",
      "[CV 4/5; 15/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 15/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough\n",
      "[CV 5/5; 15/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 16/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 1/5; 16/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 16/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 2/5; 16/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 16/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 3/5; 16/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 16/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 16/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 16/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 5/5; 16/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 17/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough\n",
      "[CV 1/5; 17/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 17/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough\n",
      "[CV 2/5; 17/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 17/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough\n",
      "[CV 3/5; 17/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 17/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough\n",
      "[CV 4/5; 17/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 17/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough\n",
      "[CV 5/5; 17/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 18/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 1/5; 18/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 18/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 2/5; 18/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 18/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 3/5; 18/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 18/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 4/5; 18/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 18/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 5/5; 18/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 19/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough\n",
      "[CV 1/5; 19/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 19/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough\n",
      "[CV 2/5; 19/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 19/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough\n",
      "[CV 3/5; 19/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 19/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough\n",
      "[CV 4/5; 19/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 19/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough\n",
      "[CV 5/5; 19/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 20/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 1/5; 20/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 20/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 2/5; 20/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 20/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 3/5; 20/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 20/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 4/5; 20/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 20/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 5/5; 20/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 21/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough\n",
      "[CV 1/5; 21/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 21/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough\n",
      "[CV 2/5; 21/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 21/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough\n",
      "[CV 3/5; 21/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 21/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough\n",
      "[CV 4/5; 21/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 21/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough\n",
      "[CV 5/5; 21/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 22/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler()\n",
      "[CV 1/5; 22/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 22/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler()\n",
      "[CV 2/5; 22/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 22/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler()\n",
      "[CV 3/5; 22/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 22/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler()\n",
      "[CV 4/5; 22/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 22/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 22/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 23/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough\n",
      "[CV 1/5; 23/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 23/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough\n",
      "[CV 2/5; 23/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 23/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough\n",
      "[CV 3/5; 23/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 23/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough\n",
      "[CV 4/5; 23/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 23/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough\n",
      "[CV 5/5; 23/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 24/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler()\n",
      "[CV 1/5; 24/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 24/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler()\n",
      "[CV 2/5; 24/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 24/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler()\n",
      "[CV 3/5; 24/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 24/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler()\n",
      "[CV 4/5; 24/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 24/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler()\n",
      "[CV 5/5; 24/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 25/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough\n",
      "[CV 1/5; 25/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 25/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough\n",
      "[CV 2/5; 25/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 25/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough\n",
      "[CV 3/5; 25/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 25/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough\n",
      "[CV 4/5; 25/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 25/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough\n",
      "[CV 5/5; 25/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 26/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler()\n",
      "[CV 1/5; 26/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 26/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler()\n",
      "[CV 2/5; 26/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 26/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler()\n",
      "[CV 3/5; 26/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 26/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler()\n",
      "[CV 4/5; 26/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 26/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler()\n",
      "[CV 5/5; 26/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 27/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough\n",
      "[CV 1/5; 27/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 27/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough\n",
      "[CV 2/5; 27/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 27/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough\n",
      "[CV 3/5; 27/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 27/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough\n",
      "[CV 4/5; 27/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 27/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough\n",
      "[CV 5/5; 27/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 28/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 1/5; 28/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 28/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 2/5; 28/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 28/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 28/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 28/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 4/5; 28/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 28/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 5/5; 28/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Pclass, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 29/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough\n",
      "[CV 1/5; 29/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 29/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough\n",
      "[CV 2/5; 29/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 29/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough\n",
      "[CV 3/5; 29/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 29/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough\n",
      "[CV 4/5; 29/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 29/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough\n",
      "[CV 5/5; 29/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 30/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 1/5; 30/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 30/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 2/5; 30/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 30/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 3/5; 30/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 30/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 4/5; 30/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 30/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 5/5; 30/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 31/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough\n",
      "[CV 1/5; 31/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 31/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough\n",
      "[CV 2/5; 31/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 31/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough\n",
      "[CV 3/5; 31/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 31/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough\n",
      "[CV 4/5; 31/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 31/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough\n",
      "[CV 5/5; 31/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 32/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 1/5; 32/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 32/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 2/5; 32/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 32/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 3/5; 32/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 32/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 4/5; 32/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 32/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 5/5; 32/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 33/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough\n",
      "[CV 1/5; 33/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 33/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough\n",
      "[CV 2/5; 33/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 33/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough\n",
      "[CV 3/5; 33/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 33/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough\n",
      "[CV 4/5; 33/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 33/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough\n",
      "[CV 5/5; 33/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 34/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 1/5; 34/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 34/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 2/5; 34/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 34/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 3/5; 34/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 34/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 34/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 34/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 5/5; 34/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 35/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough\n",
      "[CV 1/5; 35/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 35/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough\n",
      "[CV 2/5; 35/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 35/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough\n",
      "[CV 3/5; 35/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 35/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough\n",
      "[CV 4/5; 35/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 35/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough\n",
      "[CV 5/5; 35/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 36/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler()\n",
      "[CV 1/5; 36/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 36/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler()\n",
      "[CV 2/5; 36/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 36/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler()\n",
      "[CV 3/5; 36/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 36/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler()\n",
      "[CV 4/5; 36/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 36/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler()\n",
      "[CV 5/5; 36/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 37/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough\n",
      "[CV 1/5; 37/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 37/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough\n",
      "[CV 2/5; 37/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 37/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough\n",
      "[CV 3/5; 37/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 37/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough\n",
      "[CV 4/5; 37/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 37/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough\n",
      "[CV 5/5; 37/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 38/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler()\n",
      "[CV 1/5; 38/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 38/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler()\n",
      "[CV 2/5; 38/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 38/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler()\n",
      "[CV 3/5; 38/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 38/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler()\n",
      "[CV 4/5; 38/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 38/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler()\n",
      "[CV 5/5; 38/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 39/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough\n",
      "[CV 1/5; 39/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 39/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough\n",
      "[CV 2/5; 39/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 39/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough\n",
      "[CV 3/5; 39/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 39/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough\n",
      "[CV 4/5; 39/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 39/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough\n",
      "[CV 5/5; 39/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 40/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler()\n",
      "[CV 1/5; 40/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 40/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler()\n",
      "[CV 2/5; 40/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 40/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler()\n",
      "[CV 3/5; 40/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 40/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 40/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 40/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler()\n",
      "[CV 5/5; 40/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 41/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough\n",
      "[CV 1/5; 41/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 41/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough\n",
      "[CV 2/5; 41/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 41/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough\n",
      "[CV 3/5; 41/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 41/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough\n",
      "[CV 4/5; 41/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 41/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough\n",
      "[CV 5/5; 41/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 42/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 1/5; 42/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 42/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 2/5; 42/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 42/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 3/5; 42/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 42/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 4/5; 42/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 42/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 5/5; 42/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=passthrough, model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 43/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough\n",
      "[CV 1/5; 43/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 43/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough\n",
      "[CV 2/5; 43/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 43/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough\n",
      "[CV 3/5; 43/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 43/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough\n",
      "[CV 4/5; 43/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 43/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough\n",
      "[CV 5/5; 43/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 44/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 1/5; 44/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 44/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 2/5; 44/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 44/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 3/5; 44/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 44/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 4/5; 44/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 44/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler()\n",
      "[CV 5/5; 44/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.001, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 45/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough\n",
      "[CV 1/5; 45/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 45/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough\n",
      "[CV 2/5; 45/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 45/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough\n",
      "[CV 3/5; 45/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 45/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough\n",
      "[CV 4/5; 45/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 45/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough\n",
      "[CV 5/5; 45/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 46/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 1/5; 46/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 46/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 2/5; 46/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 46/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 46/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 46/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 4/5; 46/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 46/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler()\n",
      "[CV 5/5; 46/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.01, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 47/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough\n",
      "[CV 1/5; 47/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 47/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough\n",
      "[CV 2/5; 47/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 47/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough\n",
      "[CV 3/5; 47/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 47/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough\n",
      "[CV 4/5; 47/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 47/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough\n",
      "[CV 5/5; 47/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 48/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 1/5; 48/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 48/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 2/5; 48/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 48/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 3/5; 48/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 48/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 4/5; 48/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 48/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler()\n",
      "[CV 5/5; 48/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=0.1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 49/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough\n",
      "[CV 1/5; 49/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 49/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough\n",
      "[CV 2/5; 49/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 49/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough\n",
      "[CV 3/5; 49/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 49/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough\n",
      "[CV 4/5; 49/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 49/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough\n",
      "[CV 5/5; 49/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 50/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler()\n",
      "[CV 1/5; 50/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 50/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler()\n",
      "[CV 2/5; 50/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 50/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler()\n",
      "[CV 3/5; 50/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 50/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler()\n",
      "[CV 4/5; 50/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 50/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 50/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 51/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough\n",
      "[CV 1/5; 51/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 51/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough\n",
      "[CV 2/5; 51/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 51/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough\n",
      "[CV 3/5; 51/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 51/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough\n",
      "[CV 4/5; 51/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 51/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough\n",
      "[CV 5/5; 51/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 52/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler()\n",
      "[CV 1/5; 52/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 52/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler()\n",
      "[CV 2/5; 52/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 52/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler()\n",
      "[CV 3/5; 52/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 52/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler()\n",
      "[CV 4/5; 52/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 52/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler()\n",
      "[CV 5/5; 52/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=10, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 53/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough\n",
      "[CV 1/5; 53/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 53/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough\n",
      "[CV 2/5; 53/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 53/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough\n",
      "[CV 3/5; 53/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 53/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough\n",
      "[CV 4/5; 53/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 53/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough\n",
      "[CV 5/5; 53/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 54/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler()\n",
      "[CV 1/5; 54/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 54/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler()\n",
      "[CV 2/5; 54/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 54/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler()\n",
      "[CV 3/5; 54/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 54/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler()\n",
      "[CV 4/5; 54/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 54/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 54/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=100, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 1/5; 55/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough\n",
      "[CV 1/5; 55/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 2/5; 55/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough\n",
      "[CV 2/5; 55/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 3/5; 55/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough\n",
      "[CV 3/5; 55/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 4/5; 55/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough\n",
      "[CV 4/5; 55/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 5/5; 55/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough\n",
      "[CV 5/5; 55/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=passthrough;, score=nan total time=   0.0s\n",
      "[CV 1/5; 56/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 1/5; 56/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 2/5; 56/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 2/5; 56/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 3/5; 56/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 3/5; 56/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 4/5; 56/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 4/5; 56/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n",
      "[CV 5/5; 56/56] START column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler()\n",
      "[CV 5/5; 56/56] END column_drop=DropFeatures(), column_drop__columns_to_drop=Embarked, hot_encode=OneHotEncodercustom(variables=['Sex']), minmax_scaler=MinMaxScaler(), model__C=1000, std_scaler=StandardScaler();, score=nan total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 280 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1138, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'male'\n\n--------------------------------------------------------------------------------\n70 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 809, in fit\n    return self.partial_fit(X, y, sample_weight)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 844, in partial_fit\n    X = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'male'\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 420, in fit\n    return self.partial_fit(X, y)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 457, in partial_fit\n    X = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'male'\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1138, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'lower'\n\n--------------------------------------------------------------------------------\n70 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 809, in fit\n    return self.partial_fit(X, y, sample_weight)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 844, in partial_fit\n    X = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'lower'\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 420, in fit\n    return self.partial_fit(X, y)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 457, in partial_fit\n    X = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'lower'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9784/260576196.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Grid best parameter (max. accuracy): '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1373\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    850\u001b[0m                     )\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m                 \u001b[1;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[1;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             )\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 280 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1138, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'male'\n\n--------------------------------------------------------------------------------\n70 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 809, in fit\n    return self.partial_fit(X, y, sample_weight)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 844, in partial_fit\n    X = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'male'\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 420, in fit\n    return self.partial_fit(X, y)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 457, in partial_fit\n    X = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'male'\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1138, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'lower'\n\n--------------------------------------------------------------------------------\n70 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 809, in fit\n    return self.partial_fit(X, y, sample_weight)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 844, in partial_fit\n    X = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'lower'\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 420, in fit\n    return self.partial_fit(X, y)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 457, in partial_fit\n    X = self._validate_data(\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n    return np.asarray(self._values, dtype=dtype)\n  File \"C:\\Users\\dell\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 102, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'lower'\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# 'data_prep__num_pip__std_scaler': ['passthrough', StandardScaler()],\n",
    "# 'data_prep__num_pip__minmax_scaler': ['passthrough',MinMaxScaler()],\n",
    "\n",
    "#     'data_prep__st_scaler': ['passthrough', StandardScaler()],\n",
    "#     'data_prep__min_max_scaler' : ['passthrough',MinMaxScaler()]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "normal_params = {\n",
    "    \"model__C\": [0.001,0.01,0.1,1,10,100,1000],\n",
    "    'std_scaler': ['passthrough', StandardScaler()],\n",
    "    'minmax_scaler' : ['passthrough',MinMaxScaler()]\n",
    "}\n",
    "col_drop = {'column_drop' : DropFeatures(), 'column_drop_' \n",
    "    \n",
    "}\n",
    "\n",
    "params = [{**normal_params,},{}]\n",
    "\n",
    "\n",
    "\n",
    "gs = GridSearchCV(pip, params, scoring='accuracy', verbose=10)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Grid best parameter (max. accuracy): ', gs.best_params_)\n",
    "print('Grid best score (accuracy): ', gs.best_score_)\n",
    "\n",
    "#gs.best_estimator_.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "1782c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "num_pipeline = ColumnTransformer([\n",
    "    ('imputer', SimpleImputer(), ['Age']),\n",
    "#     ('st_scaler',StandardScaler(),['Fare']),\n",
    "    ],remainder='passthrough')\n",
    "\n",
    "\n",
    "#num_pipeline.fit_transform(X_train).shape\n",
    "\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"data_cleaning\",FeaturesRefiner()),\n",
    "        (\"num_pip\",num_pipeline ),\n",
    "        (\"st_scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression()),\n",
    "    ])\n",
    "\n",
    "#full_pipeline_with_predictor.fit_transform(X_train).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "23f5c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesRefiner (BaseEstimator, TransformerMixin):\n",
    "    # initializer \n",
    "    def __init__(self, hot_encoding = True, columns_to_drop=[]):\n",
    "        self.hot_encoding = hot_encoding\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df, y = None):\n",
    "        #HotEncoding Categories \n",
    "        if (self.hot_encoding):\n",
    "            list_encode = \n",
    "            for encode in list_encode:\n",
    "                ohe = OneHotEncoder()\n",
    "                transformed = ohe.fit_transform(df[[encode]])\n",
    "\n",
    "                df[ohe.categories_[0]] = transformed.toarray()\n",
    "\n",
    "\n",
    "            df = df.drop(list_encode, axis=1)\n",
    "\n",
    "\n",
    "        df = df.drop(self.columns_to_drop, axis=1)\n",
    "\n",
    "        return df\n",
    "#df = DataCleaner(hot_encoding = True, columns_to_drop=['Age']).transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "d32e30eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>middle</td>\n",
       "      <td>female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>middle</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>middle</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>middle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>middle</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>upper</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>lower</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.4625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>middle</td>\n",
       "      <td>male</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>lower</td>\n",
       "      <td>male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0542</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>upper</td>\n",
       "      <td>female</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
       "506  middle  female  33.0      0      2   26.0000        S\n",
       "303  middle  female   NaN      0      0   12.3500        Q\n",
       "149  middle    male  42.0      0      0   13.0000        S\n",
       "211  middle  female  35.0      0      0   21.0000        S\n",
       "344  middle    male  36.0      0      0   13.0000        S\n",
       "..      ...     ...   ...    ...    ...       ...      ...\n",
       "872   upper    male  33.0      0      0    5.0000        S\n",
       "205   lower  female   2.0      0      1   10.4625        S\n",
       "714  middle    male  52.0      0      0   13.0000        S\n",
       "631   lower    male  51.0      0      0    7.0542        S\n",
       "779   upper  female  43.0      0      1  211.3375        S\n",
       "\n",
       "[583 rows x 7 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09c653e6",
   "metadata": {},
   "source": [
    "## Exploring Models "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
